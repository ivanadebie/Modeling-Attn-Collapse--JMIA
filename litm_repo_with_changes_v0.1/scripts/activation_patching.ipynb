{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a69443ac-059a-4a33-8149-1bb3eacd2bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.1.2+cu121 | CUDA: True\n",
      "GPU: NVIDIA RTX 2000 Ada Generation\n",
      "Fri Aug 22 23:57:22 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 565.57.01              Driver Version: 565.57.01      CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX 2000 Ada Gene...    On  |   00000000:02:00.0 Off |                  Off |\n",
      "| 30%   26C    P8              7W /   70W |       5MiB /  16380MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "Collecting numpy<2\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.2\n",
      "    Uninstalling numpy-2.1.2:\n",
      "      Successfully uninstalled numpy-2.1.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "modeling-attn-collapse 0.1.0 requires torchaudio, which is not installed.\n",
      "xformers 0.0.23.post1 requires torch==2.1.2, but you have torch 2.3.1+cu121 which is incompatible.\n",
      "vllm 0.4.0 requires torch==2.1.2, but you have torch 2.3.1+cu121 which is incompatible.\n",
      "modeling-attn-collapse 0.1.0 requires transformers==4.39.1, but you have transformers 4.41.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Folders ready: /workspace/attention-collapse-llm\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "modeling-attn-collapse 0.1.0 requires torchaudio, which is not installed.\n",
      "modeling-attn-collapse 0.1.0 requires transformers==4.39.1, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "modeling-attn-collapse 0.1.0 requires torchaudio, which is not installed.\n",
      "vllm 0.4.0 requires torch==2.1.2, but you have torch 2.3.1+cu121 which is incompatible.\n",
      "modeling-attn-collapse 0.1.0 requires transformers==4.39.1, but you have transformers 4.41.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Installed torch/torchvision/transformer-lens/transformers\n",
      "Checking files:\n",
      "shortlist_csv -> False | /workspace/attention-collapse-llm/step5_outputs/step5_head_shortlist.csv\n",
      "plan_csv -> False | /workspace/attention-collapse-llm/step5_outputs/step5_ablation_plan.csv\n",
      "examples_csv -> False | /workspace/attention-collapse-llm/step5/merged_predictions_metrics.csv\n",
      "per_head_csv -> False | /workspace/attention-collapse-llm/data/gpt2small_attn_metrics_per_head.csv\n",
      "qa_csv -> False | /workspace/attention-collapse-llm/step5/Distractors - Sheet1.csv\n",
      "output_csv -> False | /workspace/attention-collapse-llm/step5_outputs/step5_ablation_results.csv\n",
      "Config written: /workspace/attention-collapse-llm/step5/step5_ablation_config.json\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/workspace/attention-collapse-llm/step5/Distractors - Sheet1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 66\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# 4) Merge gold answers into examples (same logic)\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m qa = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mqa_csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mQuestion\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m qa.columns \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mGold Text\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m qa.columns, \u001b[33m\"\u001b[39m\u001b[33mQA sheet must have \u001b[39m\u001b[33m'\u001b[39m\u001b[33mQuestion\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mGold Text\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     69\u001b[39m gold_map = qa.rename(columns={\u001b[33m\"\u001b[39m\u001b[33mQuestion\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mGold Text\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33mgold_answer\u001b[39m\u001b[33m\"\u001b[39m})[[\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mgold_answer\u001b[39m\u001b[33m\"\u001b[39m]].copy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/workspace/attention-collapse-llm/step5/Distractors - Sheet1.csv'"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# RunPod version of your Step 5 pipeline\n",
    "# (No Google Drive, paths changed to /workspace)\n",
    "# ============================\n",
    "\n",
    "# 0) (Optional) show GPU + environment\n",
    "import torch, platform, os, sys, json, pandas as pd\n",
    "print(\"Torch:\", torch.__version__, \"| CUDA:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "!nvidia-smi\n",
    "!pip install \"numpy<2\" --force-reinstall\n",
    "\n",
    "# 1) Set RunPod paths (replaces drive.mount + /content paths)\n",
    "import os\n",
    "ROOT = \"/workspace/attention-collapse-llm\"\n",
    "STEP5 = f\"{ROOT}/step5\"\n",
    "OUT   = f\"{ROOT}/step5_outputs\"\n",
    "DATA  = f\"{ROOT}/data\"\n",
    "os.makedirs(STEP5, exist_ok=True)\n",
    "os.makedirs(OUT,   exist_ok=True)\n",
    "os.makedirs(DATA,  exist_ok=True)\n",
    "print(\"Folders ready:\", ROOT)\n",
    "\n",
    "# 2) Clean & install compatible versions (same as your Colab)\n",
    "#    NOTE: The RunPod image already has torch; this matches your pins.\n",
    "!pip -q uninstall -y transformers torchvision torchaudio > /dev/null 2>&1\n",
    "!pip -q install --upgrade \"torch==2.3.1\" \"torchvision==0.18.1\" --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip -q install \"transformer-lens==2.7.0\" \"einops==0.8.1\" \"transformers==4.41.2\"\n",
    "print(\"Installed torch/torchvision/transformer-lens/transformers\")\n",
    "\n",
    "# 3) Paths + config (unchanged except for ROOT)\n",
    "import os, json, pandas as pd\n",
    "\n",
    "paths = {\n",
    "    \"shortlist_csv\": f\"{OUT}/step5_head_shortlist.csv\",\n",
    "    \"plan_csv\":      f\"{OUT}/step5_ablation_plan.csv\",\n",
    "    \"examples_csv\":  f\"{STEP5}/merged_predictions_metrics.csv\",\n",
    "    \"per_head_csv\":  f\"{DATA}/gpt2small_attn_metrics_per_head.csv\",\n",
    "    \"qa_csv\":        f\"{STEP5}/Distractors - Sheet1.csv\",\n",
    "    \"output_csv\":    f\"{OUT}/step5_ablation_results.csv\",\n",
    "    \"config_json\":   f\"{STEP5}/step5_ablation_config.json\",\n",
    "}\n",
    "print(\"Checking files:\")\n",
    "for k,p in paths.items():\n",
    "    if k.endswith(\"_json\"): \n",
    "        continue\n",
    "    print(k, \"->\", os.path.exists(p), \"|\", p)\n",
    "\n",
    "CFG = {\n",
    "  \"paths\": {\n",
    "    \"shortlist_csv\": paths[\"shortlist_csv\"],\n",
    "    \"plan_csv\":      paths[\"plan_csv\"],\n",
    "    \"examples_csv\":  paths[\"examples_csv\"],\n",
    "    \"per_head_csv\":  paths[\"per_head_csv\"],\n",
    "    \"output_csv\":    paths[\"output_csv\"]\n",
    "  }\n",
    "}\n",
    "with open(paths[\"config_json\"], \"w\") as f:\n",
    "    json.dump(CFG, f, indent=2)\n",
    "print(\"Config written:\", paths[\"config_json\"])\n",
    "\n",
    "# 4) Merge gold answers into examples (same logic)\n",
    "import pandas as pd, numpy as np\n",
    "\n",
    "qa = pd.read_csv(paths[\"qa_csv\"])\n",
    "assert \"Question\" in qa.columns and \"Gold Text\" in qa.columns, \"QA sheet must have 'Question' and 'Gold Text'.\"\n",
    "\n",
    "gold_map = qa.rename(columns={\"Question\":\"question\",\"Gold Text\":\"gold_answer\"})[[\"question\",\"gold_answer\"]].copy()\n",
    "gold_map[\"question\"] = gold_map[\"question\"].astype(str).str.strip()\n",
    "gold_map[\"gold_answer\"] = gold_map[\"gold_answer\"].astype(str).str.strip()\n",
    "\n",
    "ex = pd.read_csv(paths[\"examples_csv\"])\n",
    "ex[\"question\"] = ex[\"question\"].astype(str).str.strip()\n",
    "\n",
    "# Drop the existing gold_answer column from ex if it exists to avoid merge conflicts\n",
    "if \"gold_answer\" in ex.columns:\n",
    "    ex = ex.drop(columns=[\"gold_answer\"])\n",
    "\n",
    "merged = ex.merge(gold_map, on=\"question\", how=\"left\")\n",
    "merged.to_csv(paths[\"examples_csv\"], index=False)\n",
    "\n",
    "print(\"Merged gold answers into examples\")\n",
    "print(\"rows:\", len(merged), \" | missing gold:\", merged[\"gold_answer\"].isna().sum())\n",
    "display(merged.head(3))\n",
    "\n",
    "# 5) Write the runner to /workspace path (not /content)\n",
    "runner_code = r'''\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Step 5 — Head-ablation paired evaluation with lightweight collapse metrics.\n",
    "Outputs per-row before/after answers + metrics for external scoring.\n",
    "\"\"\"\n",
    "\n",
    "import os, json\n",
    "os.environ[\"TRANSFORMERS_NO_TORCHVISION\"] = \"1\"  # avoid torchvision import issues\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List, Tuple\n",
    "\n",
    "# ------------------------------\n",
    "# Load config & data\n",
    "# ------------------------------\n",
    "CFG = json.load(open(\"step5_ablation_config.json\",\"r\"))\n",
    "SHORTLIST = Path(CFG[\"paths\"][\"shortlist_csv\"])\n",
    "PLAN      = Path(CFG[\"paths\"][\"plan_csv\"])\n",
    "EXAMPLES  = Path(CFG[\"paths\"][\"examples_csv\"])\n",
    "PER_HEAD  = Path(CFG[\"paths\"][\"per_head_csv\"])\n",
    "OUTPUT    = Path(CFG[\"paths\"][\"output_csv\"])\n",
    "\n",
    "short_df = pd.read_csv(SHORTLIST)   # layer, head, _collapse_score\n",
    "plan_df  = pd.read_csv(PLAN)        # first col = row_id\n",
    "ex_df    = pd.read_csv(EXAMPLES)    # row_id, question, ctxs, model_answer, gold_answer, ...\n",
    "\n",
    "TARGETS: List[Tuple[int,int]] = [(int(r[\"layer\"]), int(r[\"head\"])) for _, r in short_df.iterrows()]\n",
    "\n",
    "# ------------------------------\n",
    "# Model & hooks\n",
    "# ------------------------------\n",
    "from transformer_lens import HookedTransformer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model  = HookedTransformer.from_pretrained(\"gpt2-small\", device=device)\n",
    "\n",
    "# ALPHA_DOSAGE scales selected heads at attn.hook_result:\n",
    "# 1.0 = no ablation, 0.5 = half-strength, 0.0 = hard-zero (full ablation).\n",
    "ALPHA_DOSAGE = 0.5\n",
    "\n",
    "def make_ablation_hooks(targets: List[Tuple[int,int]]):\n",
    "    \"\"\"Return TL forward hooks that scale selected heads at attn.hook_result by ALPHA_DOSAGE.\"\"\"\n",
    "    by_layer = {}\n",
    "    for L, H in targets:\n",
    "        by_layer.setdefault(int(L), []).append(int(H))\n",
    "    hooks = []\n",
    "    for L, heads in by_layer.items():\n",
    "        name = f\"blocks.{L}.attn.hook_result\"\n",
    "        def _mk(hlist):\n",
    "            def _fn(value, hook):\n",
    "                # value: [batch, heads, seq, d_head]\n",
    "                value[:, hlist, :, :] = value[:, hlist, :, :] * ALPHA_DOSAGE\n",
    "                return value\n",
    "            return _fn\n",
    "        hooks.append((name, _mk(heads)))\n",
    "    return hooks\n",
    "\n",
    "ABLT_HOOKS = make_ablation_hooks(TARGETS)\n",
    "\n",
    "# ------------------------------\n",
    "# Collapse metric helpers\n",
    "# ------------------------------\n",
    "def attn_entropy(attn_probs: torch.Tensor) -> float:\n",
    "    \"\"\"Mean token-wise attention entropy.\"\"\"\n",
    "    p = attn_probs.clamp_min(1e-9)\n",
    "    H = (-p * p.log()).sum(dim=-1)              # [b,h,q]\n",
    "    return H.mean().item()\n",
    "\n",
    "def effective_rank(x: torch.Tensor, energy=0.99) -> float:\n",
    "    \"\"\"Average effective rank across heads via SVD energy threshold.\"\"\"\n",
    "    b,h,s,d = x.shape\n",
    "    x2 = x.permute(1,0,2,3).contiguous().view(h, b*s, d)   # [h, N, d]\n",
    "    ranks = []\n",
    "    for i in range(h):\n",
    "        u,sing,vh = torch.linalg.svd(x2[i], full_matrices=False)\n",
    "        cum = (sing**2).cumsum(0) / (sing**2).sum()\n",
    "        r = int((cum < energy).sum().item()) + 1\n",
    "        ranks.append(r)\n",
    "    return float(sum(ranks)/len(ranks))\n",
    "\n",
    "def self_attn_ratio(attn_probs: torch.Tensor) -> float:\n",
    "    \"\"\"Mean diagonal attention mass (self-focus).\"\"\"\n",
    "    b,h,q,k = attn_probs.shape\n",
    "    diag = torch.arange(q, device=attn_probs.device)\n",
    "    mass = attn_probs[..., diag, diag]          # [b,h,q]\n",
    "    return mass.mean().item()\n",
    "\n",
    "# ------------------------------\n",
    "# Prompt & generation\n",
    "# ------------------------------\n",
    "def build_prompt(row: pd.Series) -> str:\n",
    "    \"\"\"Compose a strict copy-from-context prompt; short answers; 'I don't know' if absent.\"\"\"\n",
    "    q   = str(row.get(\"question\",\"\")).strip()\n",
    "    ctx = str(row.get(\"ctxs\",\"\")).strip()\n",
    "    return (\n",
    "        \"Answer ONLY using the context. If the answer is not explicitly in the context, reply exactly: I don't know.\\n\"\n",
    "        \"Return a SHORT answer (1–6 words), no extra text.\\n\\n\"\n",
    "        f\"Context:\\n{ctx}\\n\\nQuestion: {q}\\nAnswer:\"\n",
    "    )\n",
    "\n",
    "def greedy_generate(prompt: str, max_new_tokens: int = 16, use_ablation: bool = False,\n",
    "                    extra_hooks: List[Tuple[str, callable]] = None) -> Tuple[str, dict]:\n",
    "    \"\"\"Generate short continuation; optional head ablation; returns text and collected metrics.\"\"\"\n",
    "    toks = model.to_tokens(prompt)\n",
    "\n",
    "    # Collect attention & head-result across (possibly) ablated layers only\n",
    "    collected_attn = []\n",
    "    collected_head_out = []\n",
    "    def attn_hook(value, hook: HookPoint):\n",
    "        collected_attn.append(value.detach())\n",
    "        return value\n",
    "    def result_hook(value, hook: HookPoint):\n",
    "        collected_head_out.append(value.detach())\n",
    "        return value\n",
    "\n",
    "    # choose layers to log (keep cheap)\n",
    "    target_layers = {L for (L,_) in TARGETS} if use_ablation else {L for (L,_) in TARGETS}\n",
    "    hooks = []\n",
    "    for L in sorted(target_layers):\n",
    "        hooks.append((f\"blocks.{L}.attn.hook_attn\", attn_hook))\n",
    "        hooks.append((f\"blocks.{L}.attn.hook_result\", result_hook))\n",
    "    if extra_hooks:\n",
    "        hooks.extend(extra_hooks)\n",
    "\n",
    "    fwd = ABLT_HOOKS if use_ablation else []\n",
    "    with model.hooks(fwd_hooks=fwd + hooks):\n",
    "        out = model.generate(toks, max_new_tokens=max_new_tokens)\n",
    "\n",
    "    gen = model.to_string(out[0, toks.shape[1]:]).strip()\n",
    "\n",
    "    # metrics\n",
    "    if collected_attn:\n",
    "        attn_cat = torch.cat(collected_attn, dim=0)\n",
    "        entropy = attn_entropy(attn_cat)\n",
    "        self_ratio = self_attn_ratio(attn_cat)\n",
    "    else:\n",
    "        entropy = float(\"nan\")\n",
    "        self_ratio = float(\"nan\")\n",
    "    if collected_head_out:\n",
    "        head_cat = torch.cat(collected_head_out, dim=0)\n",
    "        erank = effective_rank(head_cat)\n",
    "    else:\n",
    "        erank = float(\"nan\")\n",
    "\n",
    "    return gen, {\"entropy\": entropy, \"erank\": erank, \"self_ratio\": self_ratio}\n",
    "\n",
    "# ------------------------------\n",
    "# Single-example evaluation\n",
    "# ------------------------------\n",
    "def evaluate_single_example(row: pd.Series, use_ablation: bool) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Run one example through GPT-2 small, optionally with head ablation.\n",
    "    Returns generated answer + collapse metrics (entropy, erank, self_ratio).\n",
    "    \"\"\"\n",
    "    prompt = build_prompt(row)\n",
    "    answer, mets = greedy_generate(prompt, max_new_tokens=16, use_ablation=use_ablation)\n",
    "    return {\n",
    "        \"row_id\": int(row[\"row_id\"]),\n",
    "        \"hallucinated\": 0,         # label comes from external F1 scorer\n",
    "        \"entropy\": float(mets[\"entropy\"]),\n",
    "        \"erank\":   float(mets[\"erank\"]),\n",
    "        \"hsim\":    float(\"nan\"),   # optional, add later\n",
    "        \"self_ratio\": float(mets[\"self_ratio\"]),\n",
    "        \"answer\": answer\n",
    "    }\n",
    "\n",
    "# ------------------------------\n",
    "# Main paired loop\n",
    "# ------------------------------\n",
    "def main():\n",
    "    plan_id_col = plan_df.columns[0]   # first col is row_id\n",
    "    plan_ids = set(plan_df[plan_id_col].tolist())\n",
    "    subset = ex_df[ex_df[\"row_id\"].isin(plan_ids)].copy().sort_values(\"row_id\")\n",
    "\n",
    "    rows = []\n",
    "    for _, row in subset.iterrows():\n",
    "        base  = evaluate_single_example(row, use_ablation=False)\n",
    "        after = evaluate_single_example(row, use_ablation=True)\n",
    "\n",
    "        rows.append({\n",
    "            \"row_id\": int(row[\"row_id\"]),\n",
    "            \"halluc_before\": int(base[\"hallucinated\"]),\n",
    "            \"halluc_after\":  int(after[\"hallucinated\"]),\n",
    "            \"d_entropy\":    (after[\"entropy\"] - base[\"entropy\"]) if (not pd.isna(base[\"entropy\"]) and not pd.isna(after[\"entropy\"])) else np.nan,\n",
    "            \"d_erank\":      (after[\"erank\"]   - base[\"erank\"])   if (not pd.isna(base[\"erank\"])   and not pd.isna(after[\"erank\"]))   else np.nan,\n",
    "            \"d_hsim\":       (after[\"hsim\"]    - base[\"hsim\"])    if (not pd.isna(base[\"hsim\"])    and not pd.isna(after[\"hsim\"]))    else np.nan,\n",
    "            \"d_self_ratio\": (after[\"self_ratio\"] - base[\"self_ratio\"]) if (not pd.isna(base[\"self_ratio\"]) and not pd.isna(after[\"self_ratio\"])) else np.nan,\n",
    "            \"answer_before\": base.get(\"answer\"),\n",
    "            \"answer_after\":  after.get(\"answer\")\n",
    "        })\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "    OUTPUT.parent.mkdir(parents=True, exist_ok=True)\n",
    "    out.to_csv(OUTPUT, index=False)\n",
    "    print(f\"[OK] Saved paired ablation results -> {OUTPUT}  (n={len(out)})\")\n",
    "    print(out[[\"row_id\",\"answer_before\",\"answer_after\"]].head(8).to_string(index=False))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "runner_path = f\"{STEP5}/step5_ablation_runner.py\"\n",
    "with open(runner_path,\"w\") as f:\n",
    "    f.write(runner_code)\n",
    "print(\"Runner written:\", runner_path)\n",
    "\n",
    "# 6) Run the runner from the /workspace path (not /content)\n",
    "import os\n",
    "os.chdir(STEP5)\n",
    "!python step5_ablation_runner.py\n",
    "\n",
    "# 7) Score with F1 and export extra tables/plots (same logic, with /workspace paths)\n",
    "import pandas as pd\n",
    "from scipy.stats import binomtest\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "res_path = paths[\"output_csv\"]\n",
    "ex_path  = paths[\"examples_csv\"]\n",
    "\n",
    "res = pd.read_csv(res_path)\n",
    "ex  = pd.read_csv(ex_path)[[\"row_id\",\"gold_answer\"]]\n",
    "df  = res.merge(ex, on=\"row_id\", how=\"left\")\n",
    "\n",
    "def normalize_text(s: str) -> str:\n",
    "    s = (s or \"\").lower().strip()\n",
    "    s = re.sub(r\"[^a-z0-9\\s]\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "def f1_match(pred: str, gold: str) -> float:\n",
    "    p = normalize_text(pred).split()\n",
    "    g = normalize_text(gold).split()\n",
    "    if not p or not g: return 0.0\n",
    "    from collections import Counter\n",
    "    pc, gc = Counter(p), Counter(g)\n",
    "    overlap = sum((pc & gc).values())\n",
    "    if overlap == 0: return 0.0\n",
    "    precision = overlap / len(p)\n",
    "    recall    = overlap / len(g)\n",
    "    return 2 * precision * recall / (precision + recall + 1e-9)\n",
    "\n",
    "# hallucination flags (1 = hallucination / F1<0.5)\n",
    "df[\"halluc_before_f1\"] = df.apply(lambda r: 1 if f1_match(str(r.get(\"answer_before\",\"\")), str(r.get(\"gold_answer\",\"\"))) < 0.5 else 0, axis=1)\n",
    "df[\"halluc_after_f1\"]  = df.apply(lambda r: 1 if f1_match(str(r.get(\"answer_after\",\"\")),  str(r.get(\"gold_answer\",\"\"))) < 0.5 else 0, axis=1)\n",
    "\n",
    "before = df[\"halluc_before_f1\"].mean()\n",
    "after  = df[\"halluc_after_f1\"].mean()\n",
    "delta  = after - before\n",
    "\n",
    "b01 = ((df[\"halluc_before_f1\"]==0) & (df[\"halluc_after_f1\"]==1)).sum()  # got worse\n",
    "b10 = ((df[\"halluc_before_f1\"]==1) & (df[\"halluc_after_f1\"]==0)).sum()  # improved\n",
    "n   = b01 + b10\n",
    "pval = binomtest(k=min(b01,b10), n=n, p=0.5, alternative=\"two-sided\").pvalue if n>0 else float(\"nan\")\n",
    "\n",
    "scored_path = f\"{OUT}/step5_ablation_results_scored.csv\"\n",
    "df.to_csv(scored_path, index=False)\n",
    "\n",
    "print(f\"Hallucination (F1<0.5) — before: {before:.3f} | after: {after:.3f} | delta: {delta:.3f}\")\n",
    "print(f\"McNemar: 0→1={b01}, 1→0={b10}, pairs={n}, p={pval:.4g}\")\n",
    "print(\"Saved scored file:\", scored_path)\n",
    "display(df.head(5))\n",
    "\n",
    "# Build master table (ablation + examples + gold)\n",
    "m = df.merge(pd.read_csv(paths[\"examples_csv\"]), on=\"row_id\", suffixes=(\"\",\"_ex\"), how=\"left\")\n",
    "\n",
    "# (Optional) if your QA sheet has metadata columns, join them here\n",
    "qa = pd.read_csv(paths[\"qa_csv\"])\n",
    "if \"Question\" in qa.columns:\n",
    "    qa[\"question\"] = qa[\"Question\"].astype(str).str.strip()\n",
    "    keep_cols = [\"question\"]\n",
    "    for cand, out_name in [\n",
    "        (\"Interference Type\",\"interference_type\"),\n",
    "        (\"Distractor Density\",\"distractor_density\"),\n",
    "        (\"Evidence Position\",\"evidence_position\"),\n",
    "        (\"Context Length\",\"context_length\"),\n",
    "    ]:\n",
    "        if cand in qa.columns:\n",
    "            qa = qa.rename(columns={cand: out_name})\n",
    "            keep_cols.append(out_name)\n",
    "    qa_meta = qa[keep_cols].copy()\n",
    "    if \"question\" in m.columns:\n",
    "        m = m.merge(qa_meta, on=\"question\", how=\"left\")\n",
    "\n",
    "master_path = f\"{OUT}/step5_analysis_master.csv\"\n",
    "m.to_csv(master_path, index=False)\n",
    "print(\"saved master:\", master_path)\n",
    "print(\"n=\", len(m), \"| before=\", m[\"halluc_before_f1\"].mean(), \"| after=\", m[\"halluc_after_f1\"].mean())\n",
    "\n",
    "# Minimal quick sanity checks on outputs\n",
    "base = ROOT\n",
    "check = [\n",
    "  f\"{base}/step5_outputs/step5_head_shortlist.csv\",\n",
    "  f\"{base}/step5_outputs/step5_ablation_plan.csv\",\n",
    "  f\"{base}/step5/merged_predictions_metrics.csv\",\n",
    "  f\"{base}/data/gpt2small_attn_metrics_per_head.csv\",\n",
    "  f\"{base}/step5/step5_ablation_config.json\",\n",
    "  f\"{base}/step5_outputs/step5_ablation_results.csv\",\n",
    "  f\"{base}/step5_outputs/step5_ablation_results_scored.csv\",\n",
    "  f\"{base}/step5_outputs/step5_analysis_master.csv\",\n",
    "]\n",
    "print({p: os.path.exists(p) for p in check})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432eea97-66be-4a51-a4e8-bc740dcf3743",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
